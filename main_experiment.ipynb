{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abedc14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TriviaQA dataset from: ../triviaqa-unfiltered/unfiltered-web-dev.json\n",
      "Loaded 531054 documents and 11313 QA pairs from TriviaQA\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def load_triviaqa(dataset_path: str) -> Tuple[Dict[str, str], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Load TriviaQA dataset and return documents and QA pairs.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to the TriviaQA JSON file (e.g., 'unfiltered-dev.json')\n",
    "        max_docs: Maximum number of documents to load\n",
    "        max_qa_pairs: Maximum number of QA pairs to load\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (documents dictionary, list of QA pairs)\n",
    "    \"\"\"\n",
    "    print(f\"Loading TriviaQA dataset from: {dataset_path}\")\n",
    "    \n",
    "    # Load the TriviaQA dataset\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)['Data']\n",
    "    \n",
    "    # Extract documents and QA pairs\n",
    "    docs = {}\n",
    "    qa_pairs = []\n",
    "    \n",
    "    for i, item in enumerate(data):\n",
    "            \n",
    "        question = item['Question']\n",
    "        answers = item['Answer']['NormalizedAliases']\n",
    "        \n",
    "        # Use the first answer as the gold answer\n",
    "        gold_answer = answers[0] if answers else item['Answer']['NormalizedValue']\n",
    "        \n",
    "        qa_pairs.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": gold_answer\n",
    "        })\n",
    "        \n",
    "        # Extract documents from Wikipedia sources\n",
    "        if 'EntityPages' in item:\n",
    "            for j, doc_info in enumerate(item['EntityPages']):\n",
    "                    \n",
    "                doc_id = f\"wiki_{doc_info['Title']}_{j}\"\n",
    "                \n",
    "                # Check if file exists\n",
    "                if 'Filename' in doc_info:\n",
    "                    doc_path = os.path.join(os.path.dirname(dataset_path), doc_info['Filename'])\n",
    "                    if os.path.exists(doc_path):\n",
    "                        try:\n",
    "                            with open(doc_path, 'r', encoding='utf-8') as doc_file:\n",
    "                                doc_content = doc_file.read()\n",
    "                                docs[doc_id] = doc_content\n",
    "                        except:\n",
    "                            # If file can't be read, use the snippet\n",
    "                            docs[doc_id] = doc_info.get('Snippet', '')\n",
    "                    else:\n",
    "                        # If file doesn't exist, use the snippet\n",
    "                        docs[doc_id] = doc_info.get('Snippet', '')\n",
    "                else:\n",
    "                    # If no filename, use the snippet\n",
    "                    docs[doc_id] = doc_info.get('Snippet', '')\n",
    "                    \n",
    "        # Add web documents if available\n",
    "        if 'SearchResults' in item:\n",
    "            for j, doc_info in enumerate(item['SearchResults']):\n",
    "                    \n",
    "                doc_id = f\"web_{j}_{doc_info.get('Title', '')}\"\n",
    "                \n",
    "                if 'Filename' in doc_info:\n",
    "                    doc_path = os.path.join(os.path.dirname(dataset_path), doc_info['Filename'])\n",
    "                    if os.path.exists(doc_path):\n",
    "                        try:\n",
    "                            with open(doc_path, 'r', encoding='utf-8') as doc_file:\n",
    "                                doc_content = doc_file.read()\n",
    "                                docs[doc_id] = doc_content\n",
    "                        except:\n",
    "                            docs[doc_id] = doc_info.get('Snippet', '')\n",
    "                    else:\n",
    "                        docs[doc_id] = doc_info.get('Snippet', '')\n",
    "                else:\n",
    "                    docs[doc_id] = doc_info.get('Snippet', '')\n",
    "    \n",
    "    print(f\"Loaded {len(docs)} documents and {len(qa_pairs)} QA pairs from TriviaQA\")\n",
    "    return docs, qa_pairs \n",
    "\n",
    "documents, qa_pairs = load_triviaqa(\"../triviaqa-unfiltered/unfiltered-web-dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a548d4c5c0c35d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T00:16:42.197109Z",
     "start_time": "2025-04-28T00:16:37.510365Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mretrievers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbm25_retriever\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BM25Retriever\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mretrievers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolbert_retriever\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColBERTRetriever\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mretrievers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdense_retriever\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DPRRetriever\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/598-ds/598_project/retrievers/bm25_retriever.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mBM25Retriever\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from retrievers.bm25_retriever import BM25Retriever\n",
    "from retrievers.colbert_retriever import ColBERTRetriever\n",
    "from retrievers.dense_retriever import DPRRetriever\n",
    "from retrievers.hybrid_retriever import HybridRetriever\n",
    "\n",
    "\n",
    "# Initialize the Retrievers with the documents\n",
    "bm25_retriever = BM25Retriever(documents)\n",
    "dense_retriever = DPRRetriever(documents)\n",
    "colbert_retriever = ColBERTRetriever(documents)\n",
    "hybrid_retriever = HybridRetriever(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a583a68580938af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T00:16:44.395789Z",
     "start_time": "2025-04-28T00:16:43.530148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k retrieved documents (BM25): ['The sky is pink', 'The sky is blue.']\n",
      "Top-k retrieved documents (DPR): ['The sky is blue.', 'The sky is pink']\n",
      "Top-k retrieved documents (ColBERT): ['The sky is blue.', 'The sky is pink']\n",
      "Top-k retrieved documents (Hybrid): ['The sky is blue.', 'The sky is pink']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Retriever with the documents\n",
    "query = \"What is the color of the sky?\"\n",
    "\n",
    "# Retrieve the top 2 most relevant documents based on the query\n",
    "top_k = 2\n",
    "bm25_retrieved_docs = bm25_retriever.retrieve(query, top_k=top_k)\n",
    "dpr_retrieved_docs = dense_retriever.retrieve(query, top_k=top_k)\n",
    "colbert_retrieved_docs = colbert_retriever.retrieve(query, top_k=top_k)\n",
    "hybrid_retrieved_docs = hybrid_retriever.retrieve(query, top_k=top_k)\n",
    "\n",
    "# Output the retrieved documents\"\n",
    "print(\"Top-k retrieved documents (BM25):\", bm25_retrieved_docs)\n",
    "print(\"Top-k retrieved documents (DPR):\", dpr_retrieved_docs)\n",
    "print(\"Top-k retrieved documents (ColBERT):\", colbert_retrieved_docs)\n",
    "print(\"Top-k retrieved documents (Hybrid):\", hybrid_retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4fbc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed-length chunks (20 tokens each):\n",
      "  01. 'The sky appears blue because molecules in the air scatter blue light from the sun more than they scatter red'\n",
      "  02. 'light. This phenomenon is called Rayleigh scattering. When the sun is lower in the sky, the light has to pass'\n",
      "  03. 'through more atmosphere, so more blue and green light is scattered away, leaving the reds and oranges we see at'\n",
      "\n",
      "Overlapping chunks (24 tokens, 8-token overlap):\n",
      "  01. 'The sky appears blue because molecules in the air scatter blue light from the sun more than they scatter red light. This phenomenon is'\n",
      "  02. 'than they scatter red light. This phenomenon is called Rayleigh scattering. When the sun is lower in the sky, the light has to pass'\n",
      "  03. 'in the sky, the light has to pass through more atmosphere, so more blue and green light is scattered away, leaving the reds and'\n",
      "  04. 'light is scattered away, leaving the reds and oranges we see at sunrise and sunset.'\n",
      "\n",
      "Semantic chunks (~120 chars, sentence-aware):\n",
      "  01. 'The sky appears blue because molecules in the air scatter blue light from the sun more than they scatter red light.'\n",
      "  02. 'This phenomenon is called Rayleigh scattering.'\n",
      "  03. 'When the sun is lower in the sky, the light has to pass through more atmosphere, so more blue and green light is scattered away, leaving the reds and oranges we see at sunrise and sunset.'\n"
     ]
    }
   ],
   "source": [
    "# --- Example text ----------------------------------------------------------\n",
    "doc = (\n",
    "    \"The sky appears blue because molecules in the air scatter blue light from \"\n",
    "    \"the sun more than they scatter red light. This phenomenon is called Rayleigh \"\n",
    "    \"scattering. When the sun is lower in the sky, the light has to pass through \"\n",
    "    \"more atmosphere, so more blue and green light is scattered away, leaving the \"\n",
    "    \"reds and oranges we see at sunrise and sunset.\"\n",
    ")\n",
    "\n",
    "# --- Import the chunkers ---------------------------------------------------\n",
    "from chunkers import FixedChunker, OverlappingChunker, SemanticChunker\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. Fixed-length chunking: split every 20 tokens (drop tail if < 20 tokens)\n",
    "fixed_chunker = FixedChunker(chunk_size=20, drop_last=True)\n",
    "fixed_chunks = fixed_chunker.chunk(doc)\n",
    "\n",
    "# 2. Overlapping windows: 24-token windows with 8-token overlap\n",
    "overlap_chunker = OverlappingChunker(chunk_size=24, overlap=8, drop_last=False)\n",
    "overlap_chunks = overlap_chunker.chunk(doc)\n",
    "\n",
    "# 3. Semantic packing: keep whole sentences, ~120 characters per chunk\n",
    "semantic_chunker = SemanticChunker(chunk_char_limit=120)\n",
    "semantic_chunks = semantic_chunker.chunk(doc)\n",
    "\n",
    "# --- Inspect the output ----------------------------------------------------\n",
    "print(\"Fixed-length chunks (20 tokens each):\")\n",
    "for i, c in enumerate(fixed_chunks, 1):\n",
    "    print(f\"  {i:02d}. {c!r}\")\n",
    "\n",
    "print(\"\\nOverlapping chunks (24 tokens, 8-token overlap):\")\n",
    "for i, c in enumerate(overlap_chunks, 1):\n",
    "    print(f\"  {i:02d}. {c!r}\")\n",
    "\n",
    "print(\"\\nSemantic chunks (~120 chars, sentence-aware):\")\n",
    "for i, c in enumerate(semantic_chunks, 1):\n",
    "    print(f\"  {i:02d}. {c!r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39985b2e30f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 0.  Imports & one-time setup\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "from collections import defaultdict\n",
    "import json, time\n",
    "\n",
    "# local modules\n",
    "from chunkers import FixedChunker, OverlappingChunker, SemanticChunker\n",
    "from retrievers import bm25_retriever, dense_retriever, hybrid_retriever\n",
    "from retrievers.dense_retriever import DPRRetriever  # example alias\n",
    "from utils.evaluation import exact_match, f1_score            # already in your repo\n",
    "from utils.timing import Timer                                 # already in your repo\n",
    "\n",
    "# external (install if missing)\n",
    "#   pip install rank-bm25 sentence-transformers faiss-cpu\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1.  Load a toy corpus\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "DOCS: Dict[str, str] = {\n",
    "    \"doc1\": Path(\"data/doc1.txt\").read_text(encoding=\"utf-8\"),\n",
    "    \"doc2\": Path(\"data/doc2.txt\").read_text(encoding=\"utf-8\"),\n",
    "    \"doc3\": Path(\"data/doc3.txt\").read_text(encoding=\"utf-8\"),\n",
    "}\n",
    "print(f\"Loaded {len(DOCS)} raw documents\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.  Choose **one** chunker recipe for this run\n",
    "#     (Swap these objects in a loop if you’re doing a grid-search)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "chunker = FixedChunker(chunk_size=128, drop_last=False)\n",
    "# chunker = OverlappingChunker(chunk_size=256, overlap=64)\n",
    "# chunker = SemanticChunker(chunk_char_limit=1500)\n",
    "\n",
    "# 2-b.  Chunk every document → corpus_chunks[id] = [chunk0, …]\n",
    "corpus_chunks: Dict[str, List[str]] = {\n",
    "    doc_id: chunker.chunk(txt) for doc_id, txt in DOCS.items()\n",
    "}\n",
    "flat_chunks = [c for chs in corpus_chunks.values() for c in chs]\n",
    "print(\n",
    "    f\"Chunked into {len(flat_chunks):,} total passages \"\n",
    "    f\"(avg {len(flat_chunks)/len(DOCS):.1f} per doc)\"\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3.  Build the four retrieval back-ends on **exactly the same chunk set**\n",
    "#     The dense & hybrid examples assume a SentenceTransformer-based DPR.\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3-a. BM25 (sparse)\n",
    "bm25_index = BM25Okapi([c.split() for c in flat_chunks])\n",
    "\n",
    "# 3-b. Dense Passage Retriever\n",
    "dpr_model = SentenceTransformer(\"facebook-dpr-ctx_encoder-multiset-base\")\n",
    "dpr_index = dense_retriever.build_faiss_index(flat_chunks, dpr_model)  # your util\n",
    "\n",
    "# 3-c. ColBERT (late interaction)  ← placeholder call\n",
    "colbert_retriever = dense_retriever.ColBERTIndexer().fit(flat_chunks)\n",
    "\n",
    "# 3-d. Hybrid (= BM25 + DPR scores)\n",
    "hybrid = hybrid_retriever.Hybrid(bm25_index, dpr_index, alpha=0.4)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4.  Query loop + simple QA evaluation\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "qa_pairs = json.loads(Path(\"data/dev_qas.json\").read_text())[:50]  # small dev slice\n",
    "K = 5\n",
    "\n",
    "results_by_system = defaultdict(list)\n",
    "\n",
    "for q in qa_pairs:\n",
    "    query, gold = q[\"question\"], q[\"answer\"]  # gold answer string\n",
    "\n",
    "    with Timer() as t:\n",
    "        top_chunks = bm25_index.get_top_n(query.split(), flat_chunks, n=K)\n",
    "    results_by_system[\"bm25\"].append(\n",
    "        {\"latency_ms\": t.ms, \"em\": exact_match(gold, top_chunks)}\n",
    "    )\n",
    "\n",
    "    with Timer() as t:\n",
    "        top_chunks = dense_retriever.search_faiss(query, dpr_index, dpr_model, top_k=K)\n",
    "    results_by_system[\"dpr\"].append(\n",
    "        {\"latency_ms\": t.ms, \"em\": exact_match(gold, top_chunks)}\n",
    "    )\n",
    "\n",
    "    with Timer() as t:\n",
    "        top_chunks = colbert_retriever.search(query, top_k=K)\n",
    "    results_by_system[\"colbert\"].append(\n",
    "        {\"latency_ms\": t.ms, \"em\": exact_match(gold, top_chunks)}\n",
    "    )\n",
    "\n",
    "    with Timer() as t:\n",
    "        top_chunks = hybrid.search(query, top_k=K)\n",
    "    results_by_system[\"hybrid\"].append(\n",
    "        {\"latency_ms\": t.ms, \"em\": exact_match(gold, top_chunks)}\n",
    "    )\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 5.  Aggregate & display – how *this* chunker impacted each retriever\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def summarise(rows):\n",
    "    return {\n",
    "        \"EM\": sum(r[\"em\"] for r in rows) / len(rows),\n",
    "        \"Latency (ms)\": sum(r[\"latency_ms\"] for r in rows) / len(rows),\n",
    "    }\n",
    "\n",
    "summary = {name: summarise(rows) for name, rows in results_by_system.items()}\n",
    "print(\"\\n===  Chunker:\", chunker.__class__.__name__, \" ===\")\n",
    "for system, metrics in summary.items():\n",
    "    print(f\"{system:7s} | EM={metrics['EM']:.3f} | Latency≈{metrics['Latency (ms)']:.1f} ms\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
