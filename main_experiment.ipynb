{
 "cells": [
  {
   "cell_type": "code",
   "id": "735019c6165dae6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T01:45:44.576508Z",
     "start_time": "2025-05-01T01:45:19.878720Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def load_triviaqa(dataset_path: str) -> Tuple[Dict[str, str], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Load TriviaQA dataset and return documents and QA pairs.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to the TriviaQA JSON file (e.g., 'unfiltered-dev.json')\n",
    "        max_docs: Maximum number of documents to load\n",
    "        max_qa_pairs: Maximum number of QA pairs to load\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (documents dictionary, list of QA pairs)\n",
    "    \"\"\"\n",
    "    print(f\"Loading TriviaQA dataset from: {dataset_path}\")\n",
    "    \n",
    "    # Load the TriviaQA dataset\n",
    "    with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)['Data']\n",
    "    \n",
    "    # Extract documents and QA pairs\n",
    "    docs = {}\n",
    "    qa_pairs = []\n",
    "    \n",
    "    for i, item in enumerate(data):\n",
    "        if len(docs)>10:\n",
    "            break\n",
    "        question = item['Question']\n",
    "        answers = item['Answer']['NormalizedAliases']\n",
    "        \n",
    "        # Use the first answer as the gold answer\n",
    "        gold_answer = answers[0] if answers else item['Answer']['NormalizedValue']\n",
    "        \n",
    "        qa_pairs.append({\n",
    "            \"question\": question,\n",
    "            \"answer\": gold_answer\n",
    "        })\n",
    "        \n",
    "        # Extract documents from Wikipedia sources\n",
    "        if 'EntityPages' in item:\n",
    "            for j, doc_info in enumerate(item['EntityPages']):\n",
    "                    \n",
    "                doc_id = f\"wiki_{doc_info['Title']}_{j}\"\n",
    "                \n",
    "                # Check if file exists\n",
    "                if 'Filename' in doc_info:\n",
    "                    doc_path = os.path.join(os.path.dirname(\"data/wikipedia\"), doc_info['Filename'])\n",
    "                    if os.path.exists(doc_path):\n",
    "                        try:\n",
    "                            with open(doc_path, 'r', encoding='utf-8') as doc_file:\n",
    "                                doc_content = doc_file.read()\n",
    "                                docs[doc_id] = doc_content\n",
    "\n",
    "                        except:\n",
    "                            # If file can't be read, use the snippet\n",
    "                            docs[doc_id] = doc_info.get('Snippet', '')\n",
    "                    else:\n",
    "                        # If file doesn't exist, use the snippet\n",
    "                        docs[doc_id] = doc_info.get('Snippet', '')\n",
    "                else:\n",
    "                    # If no filename, use the snippet\n",
    "                    docs[doc_id] = doc_info.get('Snippet', '')\n",
    "                    \n",
    "        # Add web documents if available\n",
    "        if 'SearchResults' in item:\n",
    "            for j, doc_info in enumerate(item['SearchResults']):\n",
    "                    \n",
    "                doc_id = f\"web_{j}_{doc_info.get('Title', '')}\"\n",
    "                \n",
    "                if 'Filename' in doc_info:\n",
    "                    doc_path = os.path.join(\"data/web\", doc_info['Filename'])\n",
    "                    if os.path.exists(doc_path):\n",
    "                        try:\n",
    "                            with open(doc_path, 'r', encoding='utf-8') as doc_file:\n",
    "                                doc_content = doc_file.read()\n",
    "                                docs[doc_id] = doc_content\n",
    "                        except:\n",
    "                            docs[doc_id] = doc_info.get('Snippet', '')\n",
    "                    else:\n",
    "                        docs[doc_id] = doc_info.get('Snippet', '')\n",
    "                else:\n",
    "                    docs[doc_id] = doc_info.get('Snippet', '')\n",
    "    \n",
    "    print(f\"Loaded {len(docs)} documents and {len(qa_pairs)} QA pairs from TriviaQA\")\n",
    "    return docs, qa_pairs\n",
    "\"\"\n",
    "documents, qa_pairs = load_triviaqa(\"triviaqa-unfiltered/unfiltered-web-dev.json\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TriviaQA dataset from: triviaqa-unfiltered/unfiltered-web-dev.json\n",
      "Loaded 50 documents and 1 QA pairs from TriviaQA\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T01:46:12.360179Z",
     "start_time": "2025-05-01T01:46:12.350294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i = 0\n",
    "for doc in documents.items():\n",
    "    i = i+1\n",
    "    print(f\"Document ID: {doc}\")\n",
    "    if i == 10:\n",
    "        break"
   ],
   "id": "abedc14f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: ('web_0_The Man Behind the Mask (Chipmunk Version) - YouTube', '')\n",
      "Document ID: ('web_1_Alvin & The Chipmunks - Behind The Voice Actors - Images ...', '')\n",
      "Document ID: ('web_2_The Easter Chipmunk - Cast Images | Behind The Voice Actors', '')\n",
      "Document ID: ('web_3_Alvin Seville - Alvin and the Chipmunks Wiki - Wikia', '')\n",
      "Document ID: ('web_4_Alvin and the Chipmunks (2007) - IMDb', 'Alvin and the Chipmunks (2007) - IMDb\\nIMDb\\n17 January 2017 4:34 PM, UTC\\nNEWS\\nThere was an error trying to load your rating for this title.\\nSome parts of this page won\\'t work property. Please reload or try later.\\nX Beta I\\'m Watching This!\\nKeep track of everything you watch; tell your friends.\\nError\\nAlvin and the Chipmunks\\xa0( 2007 )\\nPG |\\nA struggling songwriter named Dave Seville finds success when he comes across a trio of singing chipmunks: mischievous leader Alvin, brainy Simon, and chubby, impressionable Theodore.\\nDirector:\\nFrom $2.99 (SD) on Amazon Video\\nON\\xa0TV\\nUser Lists\\nRelated lists from IMDb users\\na list of 43 titles\\ncreated 01\\xa0Apr\\xa02012\\na list of 38 titles\\ncreated 09\\xa0May\\xa02012\\na list of 48 titles\\ncreated 20\\xa0Oct\\xa02012\\na list of 23 titles\\ncreated 06\\xa0Mar\\xa02013\\na list of 42 titles\\ncreated 30\\xa0Dec\\xa02015\\nTitle: Alvin and the Chipmunks (2007)\\n5.2/10\\nWant to share IMDb\\'s rating on your own site? Use the HTML below.\\nYou must be a registered user to use the IMDb rating plugin.\\n2 wins & 2 nominations. See more awards \\xa0»\\nVideos\\nThe world famous singing pre-teen chipmunk trio return to contend with the pressures of school, celebrity, and a rival female music group known as The Chipettes.\\nDirector: Betty Thomas\\nPlaying around while aboard a cruise ship, the Chipmunks and Chipettes accidentally go overboard and end up marooned in a tropical paradise. They discover their new turf is not as deserted as it seems.\\nDirector: Mike Mitchell\\n\\xa0 \\xa0 1 2 3 4 5 6 7 8 9 10 5.1/10 X \\xa0\\nThrough a series of misunderstandings, Alvin, Simon and Theodore come to believe that Dave is going to propose to his new girlfriend in Miami...and dump them. They have three days to get to him and stop the proposal, saving themselves not only from losing Dave but possibly from gaining a terrible stepbrother.\\nDirector: Walt Becker\\nWhen the evil wizard Gargamel chases the tiny blue Smurfs out of their village, they tumble from their magical world into New York City.\\nDirector: Raja Gosnell\\nJon Arbuckle buys a second pet, a dog named Odie. However, Odie is then abducted and it is up to Jon\\'s cat, Garfield, to find and rescue the canine.\\nDirector: Peter Hewitt\\nJon and Garfield visit the United Kingdom, where a case of mistaken cat identity finds Garfield ruling over a castle. His reign is soon jeopardized by the nefarious Lord Dargis, who has designs on the estate.\\nDirector: Tim Hill\\nThe Smurfs team up with their human friends to rescue Smurfette, who has been kidnapped by Gargamel since she knows a secret spell that can turn the evil sorcerer\\'s newest creation - creatures called the Naughties - into real Smurfs.\\nDirector: Raja Gosnell\\nStuart and Snowbell set out across town to rescue a friend.\\nDirector: Rob Minkoff\\nThe Little family adopt a charming young mouse named Stuart, but the family cat wants rid of him.\\nDirector: Rob Minkoff\\n\\xa0 \\xa0 1 2 3 4 5 6 7 8 9 10 6.2/10 X \\xa0\\nBoog, a domesticated 900lb. Grizzly bear, finds himself stranded in the woods 3 days before Open Season. Forced to rely on Elliot, a fast-talking mule deer, the two form an unlikely friendship and must quickly rally other forest animals if they are to form a rag-tag army against the hunters.\\nDirectors: Roger Allers, Jill Culton, and 1 more credit \\xa0»\\nStars: Ashton Kutcher,  Martin Lawrence,  Debra Messing\\n\\xa0 \\xa0 1 2 3 4 5 6 7 8 9 10 6.2/10 X \\xa0\\nBarry B. Benson, a bee just graduated from college, is disillusioned at his lone career choice: making honey. On a special trip outside the hive, Barry\\'s life is saved by Vanessa, a florist in New York City. As their relationship blossoms, he discovers humans actually eat honey, and subsequently decides to sue them.\\nDirectors: Steve Hickner, Simon J. Smith\\nStars: Jerry Seinfeld,  Renée Zellweger,  Matthew Broderick\\nE.B., the Easter Bunny\\'s teenage son, heads to Hollywood, determined to become a drummer in a rock \\'n\\' roll band. In LA, he\\'s taken in by Fred after the out-of-work slacker hits E.B. with his car.\\nDirector: Tim Hill\\nEdit\\nStoryline\\nIn a tree farm, three musically inclined chipmunks, Alvin, Simon and Theodore, find their tree cut down and sent to Los Angeles. Once there, they meet the frustrated songwriter David Seville, and despite a poor house wrecking first impression, they impress him with their singing talent. Seeing the opportunity for success, both human and chipmunks make a pact for them to sing his songs. While that ambition proves a frustrating struggle with the difficult trio, the dream does come true after all. However, that success presents its own trials as their unscrupulous record executive, Ian Hawke, plans to break up this family to exploit the boys. Can Dave and the Chipmunks discover what they really value amid the superficial glamor around them? Written by Kenneth Chisholm (kchishol@rogers.com)\\nThe Last Man Home.......Is Not Alone. See more \\xa0»\\nGenres:\\nRated PG for some mild rude humor | See all certifications \\xa0»\\nParents Guide:\\n14 December 2007 (USA) See more \\xa0»\\nAlso Known As:\\nAlvin y las ardillas See more \\xa0»\\nFilming Locations:\\n$44,307,417                (USA) (14 December 2007)\\nGross:\\nDid You Know?\\nTrivia\\nDavid Seville was a stage name of Ross Bagdasarian , and his son was originally supposed to portray the character in the film. He took the name \"Seville\" from the area in Spain, where he had done military service. See more »\\nGoofs\\nWhen Dave is late for work and almost forgets his pants, his old Pro Stereo skateboard is against the wall to the left of the front door. When he returns from his meeting, the board is to the right of the door and leaning in the corner. See more »\\nQuotes\\n[first lines]\\nAlvin (singing voice),\\xa0Simon (singing voice),\\xa0Theodore (singing voice): [a capella] Where is the moment we needed the most/You kick up the leaves and the magic is lost/They tell me your blue skies fade to gray/They tell me your passion\\'s gone away/And I don\\'t need no carryin\\' on/Cause you had a bad day/You\\'re taking one down/You sing a sad song just to turn it around/You say you don\\'t know/You tell me don\\'t lie/You work at a smile and you go for a ride/You had a bad day/You\\'ve seen what you like/And how does it feel for one more time/You had a bad day/...\\n[...]\\nSee more »\\nCrazy Credits\\nIn the end credits, there is a disclaimer that says \\'No chipmunks were harmed during the filming of this movie.\\' See more »\\nConnections\\nArranged by and Performed by Daniel May\\nCourtesy of Marc Ferrari/Mastersource Music Catalog\\n(Memphis, Tennessee) – See all my reviews\\n(Synopsis) Three chipmunk brothers, Alvin, Simon, and Theodore are living their lives in the forest storing nuts away for the winter when one day their tree is cut down and carried off into the city to become a Christmas tree. They must find a new home and they end up at Dave\\'s house. The only thing that makes them different is that they can talk and even sing. Dave Seville (Jason Lee) is a struggling song writer who has a great idea about making the chipmunks a new show act, singing his songs. The only thing is that you must remember is that they are chipmunks and they act like chipmunks by tearing up Dave\\'s house and interrupting his love life. However, they also begin to bond as a family with Dave becoming like a Dad. The chipmunks become a big hit and superstars with cute voices and fancy dance moves. The record company executive Ian (David Cross) sees big money in his future and takes over the act and pushes Dave to the side. Dave must try to save his little family before they becomes a show biz disaster.\\n(My Comment) I enjoyed this movie because it brought back good memories. I can\\'t believe that their first song was recorded 50 years ago. They have that certain sound that just makes you smile when you hear them. You recognize their sound immediately. The animated characters of Alvin, Simon, and Theodore are lovable now as they were 50 years ago. I always liked it when Dave would scream the name of \"Aaaaalviiiiiiiinnnnnnnnnnn!!!\" and Alvin would say \"OooooK!!!\" Those two words just make you smile. Children of all ages can see this movie without any problem. I am sure that all the parents will like it, and I know your child will, because it is a fun movie. (20th Century Fox, Run Time 1:30, Rated PG) (8/10)\\n67 of 110 people found this review helpful.\\xa0 Was this review helpful to you?\\nYes\\n')\n",
      "Document ID: ('web_5_Alvin And The Chipmunks: Behind The Movie (Exclusive) Video', '')\n",
      "Document ID: ('web_6_The Chipmunks - Biography | Billboard', 'The Chipmunks - Biography | Billboard\\nThe Chipmunks\\nAlvin Simon Theodore Ross Bagdasarian David Seville\\nPossibly the most popular TV and musical cartoon of all time, the Chipmunks enjoyed several periods of prosperity -- beginning with the \\'60s era of adolescent Baby Boomers, cresting in the \\'80s, when the Boomers\\' children were growing up, and riding the wave clear into the new millennium.\\nThe man who brought the Chipmunks to life, Ross Bagdasarian, was born on January 27, 1919, in Fresno, California. He came to Los Angeles in 1950, and appeared in the films Viva Zapata, Stalag 17, and Rear Window. Bagdasarian also worked as a songwriter, reaching the charts first in 1956, as his production of Alfi & Harry\\'s \"The Trouble with Harry\" hit number 44. He later charted two solo singles (recorded as David Seville), \"Armen\\'s Theme\" and \"Gotta Get to Your House.\" In 1958, Bagdasarian began experimenting with a novel technique -- recording normal vocals but then speeding up the playback on a tape machine. The process yielded the number one hit \"Witch Doctor\" in early 1958, and the phenomenon mushroomed later that year when his Christmas gimmick single \"The Chipmunk Song\" spent four weeks at the top of the charts. \"Alvin\\'s Harmonica\" reached number three just two months later, and Christmas reissues of \"The Chipmunk Song\" charted in the Top 40 over the next four years. The Alvin Show premiered on prime-time television in 1961, with all voices supplied by Bagdasarian. It only ran for one year, but was a success in a Saturday-morning slot. Five more Chipmunks singles charted in the early \\'60s, and five LPs also did well, including a Beatles cover album in 1964.\\nAlthough Bagdasarian died in 1972, his son Ross Jr. revived Alvin, Simon, and Theodore in 1979 on Saturday mornings and on the 1980 album Chipmunk Punk. The series became more popular than in the \\'60s, and albums of the Chipmunks singing country, Christmas, rock, and Hollywood favorites were big sellers, though they didn\\'t enjoy chart success. Although the cartoon was no longer in production by the \\'90s, new Chipmunks records continued appearing, among them 1998\\'s A-Files: Alien Files.\\nIn 2007, a film series debuted with Alvin and the Chipmunks -- the first being so successful that it spawned three sequels: 2009\\'s Alvin and the Chipmunks: The Squeakquel, 2011\\'s Alvin and the Chipmunks: Chipwrecked, and 2015\\'s Alvin and the Chipmunks 4. A revival of the TV series was also planned to premiere on Nickelodeon in early 2015. ~ John Bush, Rovi\\nRelated Artists\\n')\n",
      "Document ID: ('web_7_Alvin and the Chipmunks (2007) - Full Cast & Crew - IMDb', '')\n",
      "Document ID: ('web_8_Alvin And The Chipmunks: The Squeakquel \"Making a Scene ...', '')\n",
      "Document ID: ('web_9_Alvin and the Chipmunks: The Squeakquel | EW.com', 'Alvin and the Chipmunks: The Squeakquel – EW.com\\nComedy, Kids and Family\\nWe gave it a C-\\nIf only for the sake of adults, couldn’t the folks behind the Alvin films have had the good grace to turn Alvin and the Chipmunks: The Squeakquel into a musical? Like the original big-screen Alvin and the Chipmunks (2007), this new one is a slapstick pacifier, the kind of movie that features gags like Simon getting three-point-shotted into a wastebasket by an angry jock. Yes, griping about intentionally stupid jokes in an intentionally silly sequel seems like a churlish and rather pointless thing to do. Yet when Alvin, Simon, and Theodore take the stage to perform a number like “You Really Got Me” (sounding more like a pip-squeak Van Halen than the Kinks), or when they twirl around on top of a blender and toss off a smokin’ a cappella version of “You Spin Me Round (Like a Record),” it’s funky, charming, and — yes — irresistible. In the age of Glee and American Idol, when even little kids groove on the pop of different eras, the songs in Alvin and the Chipmunks: The Squeakquel are natural-born showstoppers.\\nThe trouble is, there are only three or four of them in the whole movie. My hopes were raised with the appearance of the Chipettes, a trio of Bambi-lashed female chipmunks who mail themselves to L.A. in a FedEx packet and sign a contract with Ian Hawk (David Cross), the evil agent-promoter from the first film. But they get to do exactly one song (it’s a goodie, “Single Ladies”). Mostly, we’re stuck with a lame plastic plot that has Alvin and his boys going to high school, plus Zachary Levi (from NBC’s Chuck, essentially taking over for Jason Lee, who makes only a token appearance) doing sub-Adam Sandler routines as the chipmunks’ caretaker. Will kids eat up this cutely fractious claptrap? Of course they will. They’ll eat up whatever you put in front of them. But that doesn’t make The Squeakquel good for them. C-\\nShow Full Article\\n')\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "a00d9182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T00:00:59.820392Z",
     "start_time": "2025-04-30T23:45:28.027937Z"
    }
   },
   "source": [
    "!pip install -r requirements.txt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anyio==4.9.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (4.9.0)\r\n",
      "Requirement already satisfied: appnope==0.1.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.1.4)\r\n",
      "Requirement already satisfied: argon2-cffi==23.1.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (23.1.0)\r\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (21.2.0)\r\n",
      "Requirement already satisfied: arrow==1.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (1.3.0)\r\n",
      "Requirement already satisfied: asttokens==3.0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (3.0.0)\r\n",
      "Requirement already satisfied: async-lru==2.0.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (2.0.5)\r\n",
      "Requirement already satisfied: attrs==25.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (25.3.0)\r\n",
      "Requirement already satisfied: babel==2.17.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (2.17.0)\r\n",
      "Requirement already satisfied: beautifulsoup4==4.13.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (4.13.4)\r\n",
      "Requirement already satisfied: bleach==6.2.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (6.2.0)\r\n",
      "Requirement already satisfied: certifi==2025.4.26 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (2025.4.26)\r\n",
      "Requirement already satisfied: cffi==1.17.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 13)) (1.17.1)\r\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 14)) (3.4.1)\r\n",
      "Requirement already satisfied: comm==0.2.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 15)) (0.2.2)\r\n",
      "Requirement already satisfied: debugpy==1.8.14 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (1.8.14)\r\n",
      "Requirement already satisfied: decorator==5.2.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 17)) (5.2.1)\r\n",
      "Requirement already satisfied: defusedxml==0.7.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 18)) (0.7.1)\r\n",
      "Requirement already satisfied: exceptiongroup==1.2.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 19)) (1.2.2)\r\n",
      "Requirement already satisfied: executing==2.2.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 20)) (2.2.0)\r\n",
      "Requirement already satisfied: fastjsonschema==2.21.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 21)) (2.21.1)\r\n",
      "Requirement already satisfied: filelock==3.18.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 22)) (3.18.0)\r\n",
      "Requirement already satisfied: fqdn==1.5.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 23)) (1.5.1)\r\n",
      "Requirement already satisfied: fsspec==2025.3.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 24)) (2025.3.2)\r\n",
      "Requirement already satisfied: h11==0.16.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 25)) (0.16.0)\r\n",
      "Requirement already satisfied: httpcore==1.0.9 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 26)) (1.0.9)\r\n",
      "Requirement already satisfied: httpx==0.28.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 27)) (0.28.1)\r\n",
      "Requirement already satisfied: huggingface-hub==0.30.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 28)) (0.30.2)\r\n",
      "Requirement already satisfied: idna==3.10 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 29)) (3.10)\r\n",
      "Requirement already satisfied: importlib_metadata==8.7.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 30)) (8.7.0)\r\n",
      "Requirement already satisfied: ipykernel==6.29.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 31)) (6.29.5)\r\n",
      "Requirement already satisfied: ipython==8.18.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 32)) (8.18.1)\r\n",
      "Requirement already satisfied: isoduration==20.11.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 33)) (20.11.0)\r\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 34)) (0.19.2)\r\n",
      "Requirement already satisfied: Jinja2==3.1.6 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 35)) (3.1.6)\r\n",
      "Requirement already satisfied: joblib==1.4.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 36)) (1.4.2)\r\n",
      "Requirement already satisfied: json5==0.12.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 37)) (0.12.0)\r\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 38)) (3.0.0)\r\n",
      "Requirement already satisfied: jsonschema==4.23.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 39)) (4.23.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications==2025.4.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 40)) (2025.4.1)\r\n",
      "Requirement already satisfied: jupyter-events==0.12.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 41)) (0.12.0)\r\n",
      "Requirement already satisfied: jupyter-lsp==2.2.5 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 42)) (2.2.5)\r\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 43)) (8.6.3)\r\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 44)) (5.7.2)\r\n",
      "Requirement already satisfied: jupyter_server==2.15.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 45)) (2.15.0)\r\n",
      "Requirement already satisfied: jupyter_server_terminals==0.5.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 46)) (0.5.3)\r\n",
      "Requirement already satisfied: jupyterlab==4.4.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 47)) (4.4.1)\r\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 48)) (0.3.0)\r\n",
      "Requirement already satisfied: jupyterlab_server==2.27.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 49)) (2.27.3)\r\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 50)) (3.0.2)\r\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 51)) (0.1.7)\r\n",
      "Requirement already satisfied: mistune==3.1.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 52)) (3.1.3)\r\n",
      "Requirement already satisfied: mpmath==1.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 53)) (1.3.0)\r\n",
      "Requirement already satisfied: nbclient==0.10.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 54)) (0.10.2)\r\n",
      "Requirement already satisfied: nbconvert==7.16.6 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 55)) (7.16.6)\r\n",
      "Requirement already satisfied: nbformat==5.10.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 56)) (5.10.4)\r\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 57)) (1.6.0)\r\n",
      "Requirement already satisfied: networkx==3.2.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 58)) (3.2.1)\r\n",
      "Requirement already satisfied: notebook==7.4.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 59)) (7.4.1)\r\n",
      "Requirement already satisfied: notebook_shim==0.2.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 60)) (0.2.4)\r\n",
      "Requirement already satisfied: numpy==2.0.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 61)) (2.0.2)\r\n",
      "Requirement already satisfied: overrides==7.7.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 62)) (7.7.0)\r\n",
      "Requirement already satisfied: packaging==25.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 63)) (25.0)\r\n",
      "Requirement already satisfied: pandocfilters==1.5.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 64)) (1.5.1)\r\n",
      "Requirement already satisfied: parso==0.8.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 65)) (0.8.4)\r\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 66)) (4.9.0)\r\n",
      "Requirement already satisfied: pillow==11.2.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 67)) (11.2.1)\r\n",
      "Requirement already satisfied: platformdirs==4.3.7 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 68)) (4.3.7)\r\n",
      "Requirement already satisfied: prometheus_client==0.21.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 69)) (0.21.1)\r\n",
      "Requirement already satisfied: prompt_toolkit==3.0.51 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 70)) (3.0.51)\r\n",
      "Requirement already satisfied: psutil==7.0.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 71)) (7.0.0)\r\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 72)) (0.7.0)\r\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 73)) (0.2.3)\r\n",
      "Requirement already satisfied: pycparser==2.22 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 74)) (2.22)\r\n",
      "Requirement already satisfied: Pygments==2.19.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 75)) (2.19.1)\r\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 76)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: python-json-logger==3.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 77)) (3.3.0)\r\n",
      "Requirement already satisfied: PyYAML==6.0.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 78)) (6.0.2)\r\n",
      "Requirement already satisfied: pyzmq==26.4.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 79)) (26.4.0)\r\n",
      "Requirement already satisfied: rank-bm25==0.2.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 80)) (0.2.2)\r\n",
      "Requirement already satisfied: referencing==0.36.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 81)) (0.36.2)\r\n",
      "Requirement already satisfied: regex==2024.11.6 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 82)) (2024.11.6)\r\n",
      "Requirement already satisfied: requests==2.32.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 83)) (2.32.3)\r\n",
      "Requirement already satisfied: rfc3339-validator==0.1.4 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 84)) (0.1.4)\r\n",
      "Requirement already satisfied: rfc3986-validator==0.1.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 85)) (0.1.1)\r\n",
      "Requirement already satisfied: rpds-py==0.24.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 86)) (0.24.0)\r\n",
      "Requirement already satisfied: safetensors==0.5.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 87)) (0.5.3)\r\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 88)) (1.6.1)\r\n",
      "Requirement already satisfied: scipy==1.13.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 89)) (1.13.1)\r\n",
      "Requirement already satisfied: Send2Trash==1.8.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 90)) (1.8.3)\r\n",
      "Requirement already satisfied: sentence-transformers==4.1.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 91)) (4.1.0)\r\n",
      "Requirement already satisfied: six==1.17.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 92)) (1.17.0)\r\n",
      "Requirement already satisfied: sniffio==1.3.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 93)) (1.3.1)\r\n",
      "Requirement already satisfied: soupsieve==2.7 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 94)) (2.7)\r\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 95)) (0.6.3)\r\n",
      "Requirement already satisfied: sympy==1.14.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 96)) (1.14.0)\r\n",
      "Requirement already satisfied: terminado==0.18.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 97)) (0.18.1)\r\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 98)) (3.6.0)\r\n",
      "Requirement already satisfied: tinycss2==1.4.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 99)) (1.4.0)\r\n",
      "Requirement already satisfied: tokenizers==0.21.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 100)) (0.21.1)\r\n",
      "Requirement already satisfied: tomli==2.2.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 101)) (2.2.1)\r\n",
      "Requirement already satisfied: torch==2.7.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 102)) (2.7.0)\r\n",
      "Requirement already satisfied: tornado==6.4.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 103)) (6.4.2)\r\n",
      "Requirement already satisfied: tqdm==4.67.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 104)) (4.67.1)\r\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 105)) (5.14.3)\r\n",
      "Requirement already satisfied: transformers==4.51.3 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 106)) (4.51.3)\r\n",
      "Requirement already satisfied: types-python-dateutil==2.9.0.20241206 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 107)) (2.9.0.20241206)\r\n",
      "Requirement already satisfied: typing_extensions==4.13.2 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 108)) (4.13.2)\r\n",
      "Requirement already satisfied: uri-template==1.3.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 109)) (1.3.0)\r\n",
      "Requirement already satisfied: urllib3==2.4.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 110)) (2.4.0)\r\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 111)) (0.2.13)\r\n",
      "Requirement already satisfied: webcolors==24.11.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 112)) (24.11.1)\r\n",
      "Requirement already satisfied: webencodings==0.5.1 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 113)) (0.5.1)\r\n",
      "Requirement already satisfied: websocket-client==1.8.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 114)) (1.8.0)\r\n",
      "Requirement already satisfied: zipp==3.21.0 in ./.venv/lib/python3.9/site-packages (from -r requirements.txt (line 115)) (3.21.0)\r\n",
      "Requirement already satisfied: setuptools>=41.1.0 in ./.venv/lib/python3.9/site-packages (from jupyterlab==4.4.1->-r requirements.txt (line 47)) (68.2.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.2.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3a548d4c5c0c35d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T00:00:43.361294Z",
     "start_time": "2025-04-30T23:45:38.784062Z"
    }
   },
   "source": [
    "from retrievers.bm25_retriever import BM25Retriever\n",
    "from retrievers.colbert_retriever import ColBERTRetriever\n",
    "from retrievers.dense_retriever import DPRRetriever\n",
    "from retrievers.hybrid_retriever import HybridRetriever\n",
    "\n",
    "\n",
    "# Initialize the Retrievers with the documents\n",
    "bm25_retriever = BM25Retriever(documents)\n",
    "dense_retriever = DPRRetriever(documents)\n",
    "colbert_retriever = ColBERTRetriever(documents)\n",
    "hybrid_retriever = HybridRetriever(documents)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Initialize the Retrievers with the documents\u001B[39;00m\n\u001B[1;32m      8\u001B[0m bm25_retriever \u001B[38;5;241m=\u001B[39m BM25Retriever(documents)\n\u001B[0;32m----> 9\u001B[0m dense_retriever \u001B[38;5;241m=\u001B[39m \u001B[43mDPRRetriever\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m colbert_retriever \u001B[38;5;241m=\u001B[39m ColBERTRetriever(documents)\n\u001B[1;32m     11\u001B[0m hybrid_retriever \u001B[38;5;241m=\u001B[39m HybridRetriever(documents)\n",
      "File \u001B[0;32m~/Desktop/598_project/retrievers/dense_retriever.py:16\u001B[0m, in \u001B[0;36mDPRRetriever.__init__\u001B[0;34m(self, documents)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext_tokenizer \u001B[38;5;241m=\u001B[39m DPRContextEncoderTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfacebook/dpr-ctx_encoder-single-nq-base\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdocuments \u001B[38;5;241m=\u001B[39m documents\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdocument_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/598_project/retrievers/dense_retriever.py:24\u001B[0m, in \u001B[0;36mDPRRetriever.encode_documents\u001B[0;34m(self, documents)\u001B[0m\n\u001B[1;32m     22\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontext_tokenizer(doc, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m'\u001B[39m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 24\u001B[0m     embedding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontext_encoder\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mpooler_output\n\u001B[1;32m     26\u001B[0m embedding \u001B[38;5;241m=\u001B[39m embedding\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mnumpy()  \u001B[38;5;66;03m# squeeze to remove batch dimension\u001B[39;00m\n\u001B[1;32m     27\u001B[0m embeddings\u001B[38;5;241m.\u001B[39mappend(embedding)\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/transformers/models/dpr/modeling_dpr.py:485\u001B[0m, in \u001B[0;36mDPRContextEncoder.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m token_type_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    483\u001B[0m     token_type_ids \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(input_shape, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m--> 485\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mctx_encoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    486\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m return_dict:\n\u001B[1;32m    496\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs[\u001B[38;5;241m1\u001B[39m:]\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/transformers/models/dpr/modeling_dpr.py:180\u001B[0m, in \u001B[0;36mDPREncoder.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    172\u001B[0m     input_ids: Tensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    178\u001B[0m     return_dict: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    179\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[BaseModelOutputWithPooling, Tuple[Tensor, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m]]:\n\u001B[0;32m--> 180\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    186\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m     sequence_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    190\u001B[0m     pooled_output \u001B[38;5;241m=\u001B[39m sequence_output[:, \u001B[38;5;241m0\u001B[39m, :]\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1144\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1137\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[1;32m   1138\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[1;32m   1139\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[1;32m   1140\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[1;32m   1141\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[1;32m   1142\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m-> 1144\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1145\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1146\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1147\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1148\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1150\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1151\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1152\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1153\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1154\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1155\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1156\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1157\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:695\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    684\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    685\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    686\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    692\u001B[0m         output_attentions,\n\u001B[1;32m    693\u001B[0m     )\n\u001B[1;32m    694\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 695\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    699\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    700\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    701\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    706\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:627\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    624\u001B[0m     cross_attn_present_key_value \u001B[38;5;241m=\u001B[39m cross_attention_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    625\u001B[0m     present_key_value \u001B[38;5;241m=\u001B[39m present_key_value \u001B[38;5;241m+\u001B[39m cross_attn_present_key_value\n\u001B[0;32m--> 627\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[43mapply_chunking_to_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    628\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed_forward_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchunk_size_feed_forward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseq_len_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_output\u001B[49m\n\u001B[1;32m    629\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    630\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (layer_output,) \u001B[38;5;241m+\u001B[39m outputs\n\u001B[1;32m    632\u001B[0m \u001B[38;5;66;03m# if decoder, return the attn key/values as the last output\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/transformers/pytorch_utils.py:253\u001B[0m, in \u001B[0;36mapply_chunking_to_forward\u001B[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;66;03m# concatenate output at same dimension\u001B[39;00m\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output_chunks, dim\u001B[38;5;241m=\u001B[39mchunk_dim)\n\u001B[0;32m--> 253\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:639\u001B[0m, in \u001B[0;36mBertLayer.feed_forward_chunk\u001B[0;34m(self, attention_output)\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfeed_forward_chunk\u001B[39m(\u001B[38;5;28mself\u001B[39m, attention_output):\n\u001B[0;32m--> 639\u001B[0m     intermediate_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mintermediate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattention_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    640\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(intermediate_output, attention_output)\n\u001B[1;32m    641\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m layer_output\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:539\u001B[0m, in \u001B[0;36mBertIntermediate.forward\u001B[0;34m(self, hidden_states)\u001B[0m\n\u001B[1;32m    538\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 539\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    540\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate_act_fn(hidden_states)\n\u001B[1;32m    541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m hidden_states\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Desktop/598_project/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a583a68580938af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T00:16:44.395789Z",
     "start_time": "2025-04-28T00:16:43.530148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k retrieved documents (BM25): ['The sky is pink', 'The sky is blue.']\n",
      "Top-k retrieved documents (DPR): ['The sky is blue.', 'The sky is pink']\n",
      "Top-k retrieved documents (ColBERT): ['The sky is blue.', 'The sky is pink']\n",
      "Top-k retrieved documents (Hybrid): ['The sky is blue.', 'The sky is pink']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Retriever with the documents\n",
    "query = \"What is the color of the sky?\"\n",
    "\n",
    "# Retrieve the top 2 most relevant documents based on the query\n",
    "top_k = 2\n",
    "bm25_retrieved_docs = bm25_retriever.retrieve(query, top_k=top_k)\n",
    "dpr_retrieved_docs = dense_retriever.retrieve(query, top_k=top_k)\n",
    "colbert_retrieved_docs = colbert_retriever.retrieve(query, top_k=top_k)\n",
    "hybrid_retrieved_docs = hybrid_retriever.retrieve(query, top_k=top_k)\n",
    "\n",
    "# Output the retrieved documents\"\n",
    "print(\"Top-k retrieved documents (BM25):\", bm25_retrieved_docs)\n",
    "print(\"Top-k retrieved documents (DPR):\", dpr_retrieved_docs)\n",
    "print(\"Top-k retrieved documents (ColBERT):\", colbert_retrieved_docs)\n",
    "print(\"Top-k retrieved documents (Hybrid):\", hybrid_retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4fbc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed-length chunks (20 tokens each):\n",
      "  01. 'The sky appears blue because molecules in the air scatter blue light from the sun more than they scatter red'\n",
      "  02. 'light. This phenomenon is called Rayleigh scattering. When the sun is lower in the sky, the light has to pass'\n",
      "  03. 'through more atmosphere, so more blue and green light is scattered away, leaving the reds and oranges we see at'\n",
      "\n",
      "Overlapping chunks (24 tokens, 8-token overlap):\n",
      "  01. 'The sky appears blue because molecules in the air scatter blue light from the sun more than they scatter red light. This phenomenon is'\n",
      "  02. 'than they scatter red light. This phenomenon is called Rayleigh scattering. When the sun is lower in the sky, the light has to pass'\n",
      "  03. 'in the sky, the light has to pass through more atmosphere, so more blue and green light is scattered away, leaving the reds and'\n",
      "  04. 'light is scattered away, leaving the reds and oranges we see at sunrise and sunset.'\n",
      "\n",
      "Semantic chunks (~120 chars, sentence-aware):\n",
      "  01. 'The sky appears blue because molecules in the air scatter blue light from the sun more than they scatter red light.'\n",
      "  02. 'This phenomenon is called Rayleigh scattering.'\n",
      "  03. 'When the sun is lower in the sky, the light has to pass through more atmosphere, so more blue and green light is scattered away, leaving the reds and oranges we see at sunrise and sunset.'\n"
     ]
    }
   ],
   "source": [
    "# --- Example text ----------------------------------------------------------\n",
    "doc = (\n",
    "    \"The sky appears blue because molecules in the air scatter blue light from \"\n",
    "    \"the sun more than they scatter red light. This phenomenon is called Rayleigh \"\n",
    "    \"scattering. When the sun is lower in the sky, the light has to pass through \"\n",
    "    \"more atmosphere, so more blue and green light is scattered away, leaving the \"\n",
    "    \"reds and oranges we see at sunrise and sunset.\"\n",
    ")\n",
    "\n",
    "# --- Import the chunkers ---------------------------------------------------\n",
    "from chunkers import FixedChunker, OverlappingChunker, SemanticChunker\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. Fixed-length chunking: split every 20 tokens (drop tail if < 20 tokens)\n",
    "fixed_chunker = FixedChunker(chunk_size=20, drop_last=True)\n",
    "fixed_chunks = fixed_chunker.chunk(doc)\n",
    "\n",
    "# 2. Overlapping windows: 24-token windows with 8-token overlap\n",
    "overlap_chunker = OverlappingChunker(chunk_size=24, overlap=8, drop_last=False)\n",
    "overlap_chunks = overlap_chunker.chunk(doc)\n",
    "\n",
    "# 3. Semantic packing: keep whole sentences, ~120 characters per chunk\n",
    "semantic_chunker = SemanticChunker(chunk_char_limit=120)\n",
    "semantic_chunks = semantic_chunker.chunk(doc)\n",
    "\n",
    "# --- Inspect the output ----------------------------------------------------\n",
    "print(\"Fixed-length chunks (20 tokens each):\")\n",
    "for i, c in enumerate(fixed_chunks, 1):\n",
    "    print(f\"  {i:02d}. {c!r}\")\n",
    "\n",
    "print(\"\\nOverlapping chunks (24 tokens, 8-token overlap):\")\n",
    "for i, c in enumerate(overlap_chunks, 1):\n",
    "    print(f\"  {i:02d}. {c!r}\")\n",
    "\n",
    "print(\"\\nSemantic chunks (~120 chars, sentence-aware):\")\n",
    "for i, c in enumerate(semantic_chunks, 1):\n",
    "    print(f\"  {i:02d}. {c!r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39985b2e30f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 0.  Imports & one-time setup\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "from collections import defaultdict\n",
    "import json, time\n",
    "\n",
    "# local modules\n",
    "from chunkers import FixedChunker, OverlappingChunker, SemanticChunker\n",
    "from retrievers import bm25_retriever, dense_retriever, hybrid_retriever\n",
    "from retrievers.dense_retriever import DPRRetriever  # example alias\n",
    "from utils.evaluation import exact_match, f1_score            # already in your repo\n",
    "from utils.timing import Timer                                 # already in your repo\n",
    "\n",
    "# external (install if missing)\n",
    "#   pip install rank-bm25 sentence-transformers faiss-cpu\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1.  Load a toy corpus\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "DOCS: Dict[str, str] = {\n",
    "    \"doc1\": Path(\"data/doc1.txt\").read_text(encoding=\"utf-8\"),\n",
    "    \"doc2\": Path(\"data/doc2.txt\").read_text(encoding=\"utf-8\"),\n",
    "    \"doc3\": Path(\"data/doc3.txt\").read_text(encoding=\"utf-8\"),\n",
    "}\n",
    "print(f\"Loaded {len(DOCS)} raw documents\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.  Choose **one** chunker recipe for this run\n",
    "#     (Swap these objects in a loop if you’re doing a grid-search)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "chunker = FixedChunker(chunk_size=128, drop_last=False)\n",
    "# chunker = OverlappingChunker(chunk_size=256, overlap=64)\n",
    "# chunker = SemanticChunker(chunk_char_limit=1500)\n",
    "\n",
    "# 2-b.  Chunk every document → corpus_chunks[id] = [chunk0, …]\n",
    "corpus_chunks: Dict[str, List[str]] = {\n",
    "    doc_id: chunker.chunk(txt) for doc_id, txt in DOCS.items()\n",
    "}\n",
    "flat_chunks = [c for chs in corpus_chunks.values() for c in chs]\n",
    "print(\n",
    "    f\"Chunked into {len(flat_chunks):,} total passages \"\n",
    "    f\"(avg {len(flat_chunks)/len(DOCS):.1f} per doc)\"\n",
    ")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3.  Build the four retrieval back-ends on **exactly the same chunk set**\n",
    "#     The dense & hybrid examples assume a SentenceTransformer-based DPR.\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3-a. BM25 (sparse)\n",
    "bm25_index = BM25Okapi([c.split() for c in flat_chunks])\n",
    "\n",
    "# 3-b. Dense Passage Retriever\n",
    "dpr_model = SentenceTransformer(\"facebook-dpr-ctx_encoder-multiset-base\")\n",
    "dpr_index = dense_retriever.build_faiss_index(flat_chunks, dpr_model)  # your util\n",
    "\n",
    "# 3-c. ColBERT (late interaction)  ← placeholder call\n",
    "colbert_retriever = dense_retriever.ColBERTIndexer().fit(flat_chunks)\n",
    "\n",
    "# 3-d. Hybrid (= BM25 + DPR scores)\n",
    "hybrid = hybrid_retriever.Hybrid(bm25_index, dpr_index, alpha=0.4)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4.  Query loop + simple QA evaluation\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "qa_pairs = json.loads(Path(\"data/dev_qas.json\").read_text())[:50]  # small dev slice\n",
    "K = 5\n",
    "\n",
    "results_by_system = defaultdict(list)\n",
    "\n",
    "for q in qa_pairs:\n",
    "    query, gold = q[\"question\"], q[\"answer\"]  # gold answer string\n",
    "\n",
    "    with Timer() as t:\n",
    "        top_chunks = bm25_index.get_top_n(query.split(), flat_chunks, n=K)\n",
    "    results_by_system[\"bm25\"].append(\n",
    "        {\"latency_ms\": t.ms, \"em\": exact_match(gold, top_chunks)}\n",
    "    )\n",
    "\n",
    "    with Timer() as t:\n",
    "        top_chunks = dense_retriever.search_faiss(query, dpr_index, dpr_model, top_k=K)\n",
    "    results_by_system[\"dpr\"].append(\n",
    "        {\"latency_ms\": t.ms, \"em\": exact_match(gold, top_chunks)}\n",
    "    )\n",
    "\n",
    "    with Timer() as t:\n",
    "        top_chunks = colbert_retriever.search(query, top_k=K)\n",
    "    results_by_system[\"colbert\"].append(\n",
    "        {\"latency_ms\": t.ms, \"em\": exact_match(gold, top_chunks)}\n",
    "    )\n",
    "\n",
    "    with Timer() as t:\n",
    "        top_chunks = hybrid.search(query, top_k=K)\n",
    "    results_by_system[\"hybrid\"].append(\n",
    "        {\"latency_ms\": t.ms, \"em\": exact_match(gold, top_chunks)}\n",
    "    )\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 5.  Aggregate & display – how *this* chunker impacted each retriever\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def summarise(rows):\n",
    "    return {\n",
    "        \"EM\": sum(r[\"em\"] for r in rows) / len(rows),\n",
    "        \"Latency (ms)\": sum(r[\"latency_ms\"] for r in rows) / len(rows),\n",
    "    }\n",
    "\n",
    "summary = {name: summarise(rows) for name, rows in results_by_system.items()}\n",
    "print(\"\\n===  Chunker:\", chunker.__class__.__name__, \" ===\")\n",
    "for system, metrics in summary.items():\n",
    "    print(f\"{system:7s} | EM={metrics['EM']:.3f} | Latency≈{metrics['Latency (ms)']:.1f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4bb226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load] TriviaQA from data/triviaqa-unfiltered/unfiltered-web-dev.json\n",
      "[load] kept 250 non-empty docs, 100 QA pairs\n",
      "[chunk] FixedChunker: 250 chunks (≈1.0 per doc)\n",
      "[dpr] encoding chunks …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dpr] Faiss index: 250 vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "retrieving: 100%|██████████| 100/100 [00:04<00:00, 22.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTS (Exact-Match evidence recall) ===\n",
      "BM25 | EM@5: 0.010 | avg latency 0.8 ms\n",
      "DPR  | EM@5: 0.000 | avg latency 43.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Minimal Retrieval-only demo on TriviaQA-unfiltered.\n",
    "\n",
    "Dependencies:\n",
    "  pip install rank-bm25 sentence-transformers faiss-cpu tqdm\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, json, gzip, time\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Retrieval libs\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss                           # CPU version is OK\n",
    "\n",
    "# Your chunkers (put the three modules in rag_pipeline/chunkers/)\n",
    "from chunkers import FixedChunker, OverlappingChunker, SemanticChunker\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "# 1. TriviaQA loader (improved)\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "def load_triviaqa(\n",
    "    dataset_path: str,\n",
    "    max_docs: int = 300,\n",
    "    max_qa_pairs: int = 100,\n",
    ") -> Tuple[Dict[str, str], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        docs   : {doc_id: raw_text}\n",
    "        qa_pairs: [{\"question\": str, \"answer\": str}, …]\n",
    "    \"\"\"\n",
    "    print(f\"[load] TriviaQA from {dataset_path}\")\n",
    "    with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)[\"Data\"]\n",
    "\n",
    "    root = Path(dataset_path).parent\n",
    "    docs: Dict[str, str] = {}\n",
    "    qa_pairs: List[Dict] = []\n",
    "\n",
    "    def read_evidence(file_path: Path) -> str:\n",
    "        if not file_path.exists():\n",
    "            return \"\"\n",
    "        # Many evidence files are .gz\n",
    "        try:\n",
    "            if file_path.suffix == \".gz\":\n",
    "                with gzip.open(file_path, \"rt\", encoding=\"utf-8\", errors=\"ignore\") as g:\n",
    "                    return g.read()\n",
    "            return file_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    def add_doc(doc_info, prefix: str, j: int):\n",
    "        if len(docs) >= max_docs:\n",
    "            return\n",
    "        doc_id = f\"{prefix}_{j}\"\n",
    "        txt = \"\"\n",
    "        if doc_info.get(\"Filename\"):\n",
    "            txt = read_evidence(root / doc_info[\"Filename\"])\n",
    "        # Fallbacks\n",
    "        txt = txt or doc_info.get(\"Snippet\", \"\") or doc_info.get(\"Title\", \"\") or doc_info.get(\"Url\", \"\")\n",
    "        docs[doc_id] = txt\n",
    "\n",
    "    for i, item in enumerate(data):\n",
    "        if i >= max_qa_pairs:\n",
    "            break\n",
    "\n",
    "        # QA\n",
    "        question = item[\"Question\"]\n",
    "        aliases = item[\"Answer\"].get(\"NormalizedAliases\") or []\n",
    "        gold = aliases[0] if aliases else item[\"Answer\"][\"NormalizedValue\"]\n",
    "        qa_pairs.append({\"question\": question, \"answer\": gold})\n",
    "\n",
    "        # Wiki evidence\n",
    "        for j, d in enumerate(item.get(\"EntityPages\", [])):\n",
    "            add_doc(d, f\"wiki_{d.get('Title','wiki')}\", j)\n",
    "        # Web search evidence\n",
    "        for j, d in enumerate(item.get(\"SearchResults\", [])):\n",
    "            add_doc(d, \"web\", j)\n",
    "\n",
    "    # Drop empties\n",
    "    docs = {k: v for k, v in docs.items() if v.strip()}\n",
    "    print(f\"[load] kept {len(docs)} non-empty docs, {len(qa_pairs)} QA pairs\")\n",
    "    return docs, qa_pairs\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "# 2. Exact-Match helper\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "def exact_match(gold: str, passages: List[str]) -> int:\n",
    "    g = gold.lower()\n",
    "    return int(any(g in p.lower() for p in passages))\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "# 3. Main\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "def main():\n",
    "    # -------- paths & params ------------------------------------------------\n",
    "    TQA_JSON = \"data/triviaqa-unfiltered/unfiltered-web-dev.json\"   # edit if needed\n",
    "    MAX_DOCS = 300\n",
    "    MAX_QA   = 100\n",
    "    TOP_K    = 5\n",
    "\n",
    "    # -------- load ----------------------------------------------------------\n",
    "    docs, qa_pairs = load_triviaqa(TQA_JSON, MAX_DOCS, MAX_QA)\n",
    "    if not docs:\n",
    "        raise RuntimeError(\"No non-empty docs – check dataset path / permissions\")\n",
    "\n",
    "    # -------- choose chunker ------------------------------------------------\n",
    "    chunker = FixedChunker(chunk_size=128, drop_last=False)\n",
    "    # chunker = OverlappingChunker(chunk_size=256, overlap=64)\n",
    "    # chunker = SemanticChunker(chunk_char_limit=1500)\n",
    "\n",
    "    chunk_texts, chunk_to_doc = [], []\n",
    "    for doc_id, txt in docs.items():\n",
    "        for ch in chunker.chunk(txt):\n",
    "            chunk_texts.append(ch)\n",
    "            chunk_to_doc.append(doc_id)\n",
    "\n",
    "    print(f\"[chunk] {chunker.__class__.__name__}: {len(chunk_texts)} chunks \"\n",
    "          f\"(≈{len(chunk_texts)/len(docs):.1f} per doc)\")\n",
    "\n",
    "    # -------- BM25 ----------------------------------------------------------\n",
    "    bm25 = BM25Okapi([c.split() for c in chunk_texts])\n",
    "\n",
    "    # -------- DPR -----------------------------------------------------------\n",
    "    model = SentenceTransformer(\"facebook-dpr-ctx_encoder-multiset-base\")\n",
    "    print(\"[dpr] encoding chunks …\")\n",
    "    ctx_emb = model.encode(\n",
    "        chunk_texts,\n",
    "        batch_size=64,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "    )\n",
    "    index = faiss.IndexFlatIP(ctx_emb.shape[1])\n",
    "    index.add(ctx_emb)\n",
    "    print(f\"[dpr] Faiss index: {index.ntotal} vectors\")\n",
    "\n",
    "    # -------- retrieval loop ------------------------------------------------\n",
    "    bm25_hits = dpr_hits = 0\n",
    "    bm25_lat, dpr_lat = [], []\n",
    "\n",
    "    for qa in tqdm(qa_pairs, desc=\"retrieving\"):\n",
    "        q, gold = qa[\"question\"], qa[\"answer\"]\n",
    "\n",
    "        # BM25\n",
    "        t0 = time.perf_counter()\n",
    "        ids = bm25.get_top_n(q.split(), list(range(len(chunk_texts))), n=TOP_K)\n",
    "        bm25_lat.append((time.perf_counter() - t0) * 1e3)\n",
    "        bm25_hits += exact_match(gold, [chunk_texts[i] for i in ids])\n",
    "\n",
    "        # DPR\n",
    "        t0 = time.perf_counter()\n",
    "        q_emb = model.encode([q], normalize_embeddings=True)\n",
    "        _, idxs = index.search(q_emb, TOP_K)\n",
    "        dpr_lat.append((time.perf_counter() - t0) * 1e3)\n",
    "        dpr_hits += exact_match(gold, [chunk_texts[i] for i in idxs[0]])\n",
    "\n",
    "    # -------- summary -------------------------------------------------------\n",
    "    n = len(qa_pairs)\n",
    "    print(\"\\n=== RESULTS (Exact-Match evidence recall) ===\")\n",
    "    print(f\"BM25 | EM@{TOP_K}: {bm25_hits/n:.3f} | avg latency {np.mean(bm25_lat):.1f} ms\")\n",
    "    print(f\"DPR  | EM@{TOP_K}: {dpr_hits/n:.3f} | avg latency {np.mean(dpr_lat):.1f} ms\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
